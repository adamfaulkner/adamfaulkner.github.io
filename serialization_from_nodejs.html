<head>
    <title> Serialization From NodeJS </title>

<style type="text/css">

body {
margin:40px auto;
max-width: 800px;
line-height:1.6;
font-size:18px;
padding:0 10px
}

h1,h2,h3{
  line-height:1.2
}

img {
 width: 800px;
}

.chart-container {
    position: relative;
    width: 600px;
    height: 300px;
    margin: 20px auto;
}

</style>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
    <script type="text/javascript">
    // Final Serialize Duration
    // Serializer	Avg (ms)
    // ------------------------
    // json      	1440.67
    // msgpack   	713.00
    // cbor      	716.65
    // proto     	5532.67
    // avro      	586.67
    // bebop     	2700.67
    // flatbuffers	3723.00
    // pbf       	563.33
    //
    // Unoptimized Serializer Duration
    // Serializer	Avg (ms)
    // ------------------------
    // json      	1415.33
    // msgpack   	910.67
    // cbor      	1335.67
    // proto     	5582.33
    // avro      	5443.33
    // bebop     	12351.00
    // flatbuffers	3674.00
    const serializationStats = [
      {"name":"json","rustSerializeDuration":458, "finalSerializeDuration": 1440.67, "unoptimizedSerializeDuration": 1415.33 },
      {"name":"protobuf.js","rustSerializeDuration":281, "finalSerializeDuration": 5532.67, "unoptimizedSerializeDuration": 5582.33 },
      {"name":"pbf","rustSerializeDuration":281, "finalSerializeDuration": 563.33, "unoptimizedSerializeDuration": 563.33 },
      {"name":"msgpack","rustSerializeDuration":287, "finalSerializeDuration": 713.00, "unoptimizedSerializeDuration": 910.67 },
      {"name":"cbor","rustSerializeDuration":331, "finalSerializeDuration": 716.65, "unoptimizedSerializeDuration": 1335.67 },
      {"name":"bebop","rustSerializeDuration":190, "finalSerializeDuration": 2700.67, "unoptimizedSerializeDuration": 12351.00 },
      {"name":"avro","rustSerializeDuration":321, "finalSerializeDuration": 586.67, "unoptimizedSerializeDuration": 5443.33 },
    ];
    function createFinalResultsChart() {
      const canvas = document.getElementById('finalResultsChart');
      canvas.width = 600;
      canvas.height = 300;
      const ctx = canvas.getContext('2d');
      const sortedStats = [...serializationStats].sort((a, b) => a.finalSerializeDuration - b.finalSerializeDuration);
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: sortedStats.map(stat => stat.name),
          datasets: [{
            label: 'Final Serialization Duration (ms)',
            data: sortedStats.map(stat => stat.finalSerializeDuration),
            backgroundColor: 'rgba(54, 162, 235, 0.8)',
            borderColor: 'rgba(54, 162, 235, 1)',
            borderWidth: 1
          }]
        },
        options: {
          responsive: false,
          maintainAspectRatio: false,
          scales: {
            y: {
              beginAtZero: true,
              title: {
                display: true,
                text: 'Duration (ms)'
              }
            }
          },
          plugins: {
            title: {
              display: true,
              text: 'Final Serialization Performance Comparison'
            }
          }
        }
      });
    }
    function createPreOptimizationChart() {
      const canvas = document.getElementById('preOptimizationChart');
      canvas.width = 600;
      canvas.height = 300;
      const ctx = canvas.getContext('2d');
      const formats = ['msgpack', 'cbor', 'bebop', 'avro'];
      const filteredStats = serializationStats.filter(stat => formats.includes(stat.name));
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: filteredStats.map(stat => stat.name),
          datasets: [{
            label: 'Unoptimized Duration (ms)',
            data: filteredStats.map(stat => stat.unoptimizedSerializeDuration),
            backgroundColor: 'rgba(255, 99, 132, 0.8)',
            borderColor: 'rgba(255, 99, 132, 1)',
            borderWidth: 1
          }, {
            label: 'Final Optimized Duration (ms)',
            data: filteredStats.map(stat => stat.finalSerializeDuration),
            backgroundColor: 'rgba(75, 192, 192, 0.8)',
            borderColor: 'rgba(75, 192, 192, 1)',
            borderWidth: 1
          }]
        },
        options: {
          responsive: false,
          maintainAspectRatio: false,
          scales: {
            y: {
              beginAtZero: true,
              title: {
                display: true,
                text: 'Duration (ms)'
              }
            }
          },
          plugins: {
            title: {
              display: true,
              text: 'Pre-Optimization vs Post-Optimization Comparison'
            }
          }
        }
      });
    }
    function createBebopChart() {
      const canvas = document.getElementById('bebopChart');
      canvas.width = 600;
      canvas.height = 300;
      const ctx = canvas.getContext('2d');
      const bebopStat = serializationStats.find(stat => stat.name === 'bebop');
      const jsonStat = serializationStats.find(stat => stat.name === 'json');
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: ['Bebop Pre-Optimize', 'Bebop Optimized', 'JSON'],
          datasets: [{
            label: 'Serialization Duration (ms)',
            data: [bebopStat.unoptimizedSerializeDuration, bebopStat.finalSerializeDuration, jsonStat.finalSerializeDuration],
            backgroundColor: [
              'rgba(255, 99, 132, 0.8)',
              'rgba(75, 192, 192, 0.8)',
              'rgba(255, 206, 86, 0.8)'
            ],
            borderColor: [
              'rgba(255, 99, 132, 1)',
              'rgba(75, 192, 192, 1)',
              'rgba(255, 206, 86, 1)'
            ],
            borderWidth: 1
          }]
        },
        options: {
          responsive: false,
          maintainAspectRatio: false,
          scales: {
            y: {
              beginAtZero: true,
              title: {
                display: true,
                text: 'Duration (ms)'
              }
            }
          },
          plugins: {
            title: {
              display: true,
              text: 'Bebop Performance: Pre-Optimize vs Optimized vs JSON'
            }
          }
        }
      });
    }
    function createProtobufChart() {
      const canvas = document.getElementById('protobufChart');
      canvas.width = 600;
      canvas.height = 300;
      const ctx = canvas.getContext('2d');
      const protobufStat = serializationStats.find(stat => stat.name === 'protobuf.js');
      const pbfStat = serializationStats.find(stat => stat.name === 'pbf');
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: ['Protobuf.js (Optimized)', 'Pbf (Optimized)'],
          datasets: [{
            label: 'Serialization Duration (ms)',
            data: [protobufStat.finalSerializeDuration, pbfStat.finalSerializeDuration],
            backgroundColor: [
              'rgba(153, 102, 255, 0.8)',
              'rgba(255, 159, 64, 0.8)'
            ],
            borderColor: [
              'rgba(153, 102, 255, 1)',
              'rgba(255, 159, 64, 1)'
            ],
            borderWidth: 1
          }]
        },
        options: {
          responsive: false,
          maintainAspectRatio: false,
          scales: {
            y: {
              beginAtZero: true,
              title: {
                display: true,
                text: 'Duration (ms)'
              }
            }
          },
          plugins: {
            title: {
              display: true,
              text: 'Protobuf.js vs Pbf Performance Comparison'
            }
          }
        }
      });
    }
    function createRustChart() {
      const canvas = document.getElementById('rustChart');
      canvas.width = 600;
      canvas.height = 300;
      const ctx = canvas.getContext('2d');
      const sortedStats = [...serializationStats].sort((a, b) => a.rustSerializeDuration - b.rustSerializeDuration);
      new Chart(ctx, {
        type: 'bar',
        data: {
          labels: sortedStats.map(stat => stat.name),
          datasets: [{
            label: 'Rust Implementation (ms)',
            data: sortedStats.map(stat => stat.rustSerializeDuration),
            backgroundColor: 'rgba(255, 99, 132, 0.8)',
            borderColor: 'rgba(255, 99, 132, 1)',
            borderWidth: 1
          }, {
            label: 'JavaScript Optimized (ms)',
            data: sortedStats.map(stat => stat.finalSerializeDuration),
            backgroundColor: 'rgba(54, 162, 235, 0.8)',
            borderColor: 'rgba(54, 162, 235, 1)',
            borderWidth: 1
          }]
        },
        options: {
          responsive: false,
          maintainAspectRatio: false,
          scales: {
            y: {
              beginAtZero: true,
              title: {
                display: true,
                text: 'Duration (ms)'
              }
            }
          },
          plugins: {
            title: {
              display: true,
              text: 'Rust vs JavaScript Optimized Performance'
            }
          }
        }
      });
    }
    document.addEventListener('DOMContentLoaded', function() {
      createFinalResultsChart();
      createPreOptimizationChart();
      createBebopChart();
      createProtobufChart();
      createRustChart();
    });
    </script>
</head>


<h1>Serialization from NodeJS</h1>
<p>2025-06-22</p>
<h2>Introduction</h2>
<p>In this post, I&#39;ll show that several binary formats outperform JSON at
serialization in NodeJS. However, Node&#39;s runtime and library ecosystem introduce
complexity that must be dealt with to achieve this performance.</p>
<p>This is intended as a companion to <a href="binary_formats_are_better_than_json_in_browsers.html">Binary Formats are Better than JSON in
Browsers</a>. In that post, I
explored how several binary formats outperfom JSON in browsers. In this post,
I&#39;ll be focused on serialization performance in backend services written in
NodeJS.</p>
<p>For all of these tests, the code is available
<a href="https://github.com/adamfaulkner/serialization_from_nodejs">here</a>. I used the
<a href="https://citibikenyc.com/system-data">NYC citibike dataset</a> as my data for
benchmarking. In my benchmark, I serialize a list of 100,000 trips in different
serialization formats.</p>
<p>Here are the final results, comparing the formats that I tested:</p>
<div id="finalResults">
<div class="chart-container">
<canvas id="finalResultsChart"></canvas>
</div>
</div>

<h2>Why is this interesting?</h2>
<p>Naively, one would assume that binary formats are always better than JSON, since
they produce a smaller output, and fewer bytes ought to be faster. However, JSON
serialization is implemented in C++ as part of v8, and can make use of
optimizations that are not available to other libraries. A library like
<a href="https://github.com/mtth/avsc">avsc</a> is implemented in pure JavaScript, and so
has fewer optimization opportunities.</p>
<p>In a past job, I wrote a doc about how avro didn&#39;t perform as well as JSON for
serialization, so we shouldn&#39;t use it. This seems to no longer be the case, so I
wanted to write this follow up.</p>
<p>I also found that it was important to optimize a couple of things in the
serialization benchmark to get a good result. Without optimization, some of
these serializers were 10x slower. I wanted to document this somewhere, in case
it is helpful.</p>
<h2>Optimizations</h2>
<p>At the beginning of these tests, the results were radically different from the eventual optimized versions:</p>
<div id="preOptimizationComparisons">
<div class="chart-container">
<canvas id="preOptimizationChart"></canvas>
</div>
</div>

<p>There were two big changes that I made to several of these serializers which were responsible for this speedup:</p>
<ul>
<li>Create less garbage when setting up the object to serialize.</li>
<li>Pre-allocate appropriately sized buffers.</li>
</ul>
<h3>Profiling and Allocation Sampling:</h3>
<p>When I started CPU profiling this benchmark, it became very clear that we were
spending almost all of our time inside the garbage collector. I quickly switched
to looking at allocation sampling. Node makes this very easy using the
<a href="https://nodejs.org/api/inspector.html">inspector</a> module -- third party
libraries are no longer required for doing scoped profiling!</p>
<p>Allocation sampling clearly showed that most of this garbage was created in the
two aforementioned places: when setting up the object to serialize, and when
growing buffers.</p>
<h3>Creating the input to the serializer without creating lots of garbage.</h3>
<p>The first thing I noticed when optimizing this code was that we were creating
most of our garbage when setting up the object for serialization. This is code
that looked like this:</p>
<pre><code class="language-typescript">
	const response = {
		trips: trips.map((trip) =&gt; ({
			rideId: trip.rideId,
			rideableType: mapToAvroRideableType(trip.rideableType),
			startLat: trip.startLat || null,
			...
		})),
	};
</code></pre>
<p>This code was responsible for mapping between our internal types and the types
expected by our Avro schema. In this case, I needed to replace some <code>undefined</code>
with <code>null</code>, and remap enums. In other cases, I needed to slightly rename
fields, like <code>startTime</code> became <code>startTimeMs</code>.</p>
<p>At any rate, this created a huge amount of garbage, which bogged down our benchmark.</p>
<p>I was able to fix these by creating &quot;remapper types&quot;, which looked like this:</p>
<pre><code class="language-typescript">class AvroTripTransformer {
	constructor(private underlying: Trip) {}

	get rideId(): string {
		return this.underlying.rideId;
	}

	get rideableType(): string {
		return mapToAvroRideableType(this.underlying.rideableType);
	}

	get startLat(): number | null {
		return this.underlying.startLat || null;
	}
	...
}
</code></pre>
<p>This mostly eliminated the garbage created by these objects, which more than
doubled the speed of the avro benchmark. Other serializers had a noticeable, but
less dramatic speedup.</p>
<h3>Using an appropriately sized buffer.</h3>
<p>The second big thing I noticed was that many serializers allocated a lot of
buffers. Most of the libraries that I looked at closely implemented dynamically
growing buffers by allocating a new buffer double the size of the original
buffer when it was full, and copying the data into the new buffer. This is a lot
of wasted effort in JavaScript, where Uint8Arrays are weirdly expensive relative
to other languages.</p>
<p>Some of these libraries permitted us to provide a buffer for the serializer to
use instead, so I could simply allocate a large enough buffer up front, and
avoid this cost.</p>
<p>It seems to me that all of these libraries ought to just compute the length of
the serialized message first, then allocate an appropriately sized buffer,
rather than trying to dynamically grow buffers.</p>
<p><a href="https://github.com/mtth/avsc/tree/master">Avsc</a> essentially does this, but in
an inefficient way. Its underlying <a href="https://github.com/mtth/avsc/blob/91d653f72906102448a059cb81692177bb678f52/lib/utils.js#L518-L525"><code>Tap</code>
implementation</a>
will silently overflow when presented with an object that is too big to
serialize. It will then explicitly allocate an appropriately sized buffer, and
repeat the serialization operation into this buffer. It would probably be faster
to have an explicit way to determine the size of a serialized message.</p>
<p>Other libraries, like <a href="https://github.com/kriszyp/msgpackr">Msgpackr</a> do not
have a way to provide an appropriately sized buffer, but they do permit us to
reuse a buffer previously returned by a prior call to msgpacker. By using this
method and repeating the test a number of times, we can amortize out the initial
attempt which grows the buffer dynamically.</p>
<h2>Serializer Specific Observations</h2>
<h3>Bebop</h3>
<div id="bebopPreOptimizeVsOptimizeVsJSON">
<div class="chart-container">
<canvas id="bebopChart"></canvas>
</div>
</div>

<p>While I was able to speed up Bebop considerably, it was still much slower than
JSON. It didn&#39;t have a reasonable way to provide a pre-allocated buffer to the
serializer. I suspect this would help considerably.</p>
<h3>Protobuf.js</h3>
<p><a href="https://github.com/protobufjs/protobuf.js">Protobuf.js</a> does not have a good API
for avoiding garbage during setup. It requires creating explicit, library
specific, <code>Message</code> objects, which we can&#39;t easily fake to avoid creating
garbage.</p>
<p>Protobuf.js <a href="https://github.com/protobufjs/protobuf.js/blob/f42297b29d15c8e0382744a83f5147a1aa978f42/src/writer.js#L448-L459">avoids the issues with dynamically growing buffers out of the
box</a>.
However, this appears to be at the cost of a much more complicated
implementation. Garbage collection still accounts for a 85% of the time spent
serializing protobuf messages with Protobuf.js, so I&#39;d guess that this optimized
implementation costs more than it saves.</p>
<p>This situation with Protobuf.js is unfortunate. There&#39;s nothing in the Protobuf
format that requires the serializer to be this slow.</p>
<p>I tried another library called <a href="https://github.com/mapbox/pbf">Pbf</a>, and it was
an order of magnitude faster. It was also around 88% smaller than Protobuf.js,
by lines of code. The code it generated was very easy to read and understand.</p>
<div id="protobufVsPbf">
<div class="chart-container">
<canvas id="protobufChart"></canvas>
</div>
</div>

<p>To make a broad generalization, I&#39;ve seen this kind of pattern with many
JavaScript libraries. They are not designed with performance in mind, and end up
having poor performance characteristics.</p>
<h2>Use a Different Programming Language</h2>
<p>Compared with minimally optimized Rust code, JavaScript is just very slow. This
is not surprising at all, but I think it bears remembering. If you have a
choice, don&#39;t use JavaScript on the server.</p>
<div id="rustVsOptimized">
<div class="chart-container">
<canvas id="rustChart"></canvas>
</div>
</div>

<p>Note that all of this high performance JavaScript is rather subtle, and requires
using a profiler and carefully weighing tradeoffs. I think it&#39;s probably harder
to write this kind of JavaScript than it is to just use a compiled language with
better performance characteristics, like Rust. Obviously, there are situations
where NodeJS is a requirement, but it&#39;d be best to just not use this for
anything that needs to perform well.</p>
<h2>Conclusion</h2>
<ul>
<li>There are a number of serialization libraries that outperform JSON in NodeJS.</li>
<li>It&#39;s important to avoid generating extraneous garbage when doing these kinds of benchmarks.</li>
<li>It&#39;s important to provide an appropriately sized buffer when performing serialization.</li>
<li>If you care about serialization performance, consider using a different programming language with better tradeoffs.</li>
</ul>
